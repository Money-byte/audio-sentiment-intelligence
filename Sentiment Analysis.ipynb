{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113af170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (0.10.2.post1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Aprajit Sharma\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Aprajit Sharma\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Aprajit Sharma\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Aprajit Sharma\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Aprajit Sharma\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Aprajit Sharma\\AppData\\Roaming\\Python\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.1->librosa) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.1->librosa) (23.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aprajit sharma\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aprajit sharma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030a8f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature data shape: (2880, 1070)\n",
      "Labels shape: (2880,)\n",
      "x_train shape: (2016, 1070, 1)\n",
      "y_train shape: (2016, 8)\n",
      "x_test shape: (864, 1070, 1)\n",
      "y_test shape: (864, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aprajit Sharma\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.1943 - loss: 2.2999 - val_accuracy: 0.2921 - val_loss: 1.7361\n",
      "Epoch 2/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.3657 - loss: 1.6723 - val_accuracy: 0.3366 - val_loss: 1.5964\n",
      "Epoch 3/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.4052 - loss: 1.5178 - val_accuracy: 0.3960 - val_loss: 1.5488\n",
      "Epoch 4/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.4525 - loss: 1.4448 - val_accuracy: 0.3911 - val_loss: 1.5159\n",
      "Epoch 5/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.4917 - loss: 1.3579 - val_accuracy: 0.4653 - val_loss: 1.4105\n",
      "Epoch 6/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4958 - loss: 1.3413 - val_accuracy: 0.4505 - val_loss: 1.4025\n",
      "Epoch 7/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.5439 - loss: 1.2518 - val_accuracy: 0.4950 - val_loss: 1.3160\n",
      "Epoch 8/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5463 - loss: 1.2198 - val_accuracy: 0.5248 - val_loss: 1.2677\n",
      "Epoch 9/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5653 - loss: 1.2090 - val_accuracy: 0.4703 - val_loss: 1.2527\n",
      "Epoch 10/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5626 - loss: 1.1319 - val_accuracy: 0.5198 - val_loss: 1.1812\n",
      "Epoch 11/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6118 - loss: 1.0445 - val_accuracy: 0.5941 - val_loss: 1.1152\n",
      "Epoch 12/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6223 - loss: 1.0286 - val_accuracy: 0.5297 - val_loss: 1.1276\n",
      "Epoch 13/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6537 - loss: 0.9200 - val_accuracy: 0.5446 - val_loss: 1.0816\n",
      "Epoch 14/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6626 - loss: 0.9374 - val_accuracy: 0.5644 - val_loss: 0.9989\n",
      "Epoch 15/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6593 - loss: 0.8817 - val_accuracy: 0.6139 - val_loss: 0.9591\n",
      "Epoch 16/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6954 - loss: 0.8276 - val_accuracy: 0.6436 - val_loss: 0.9920\n",
      "Epoch 17/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6902 - loss: 0.8603 - val_accuracy: 0.6782 - val_loss: 0.8994\n",
      "Epoch 18/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7114 - loss: 0.7933 - val_accuracy: 0.6386 - val_loss: 0.9665\n",
      "Epoch 19/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7222 - loss: 0.7608 - val_accuracy: 0.6881 - val_loss: 0.8783\n",
      "Epoch 20/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7286 - loss: 0.7484 - val_accuracy: 0.6832 - val_loss: 0.8891\n",
      "Epoch 21/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7425 - loss: 0.7121 - val_accuracy: 0.6535 - val_loss: 0.8929\n",
      "Epoch 22/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7586 - loss: 0.6662 - val_accuracy: 0.6980 - val_loss: 0.8395\n",
      "Epoch 23/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7699 - loss: 0.6265 - val_accuracy: 0.6980 - val_loss: 0.7521\n",
      "Epoch 24/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7882 - loss: 0.5961 - val_accuracy: 0.7277 - val_loss: 0.7686\n",
      "Epoch 25/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7814 - loss: 0.6070 - val_accuracy: 0.7327 - val_loss: 0.7500\n",
      "Epoch 26/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8174 - loss: 0.5513 - val_accuracy: 0.7327 - val_loss: 0.7235\n",
      "Epoch 27/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7871 - loss: 0.5989 - val_accuracy: 0.7525 - val_loss: 0.7520\n",
      "Epoch 28/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8082 - loss: 0.5487 - val_accuracy: 0.7228 - val_loss: 0.7442\n",
      "Epoch 29/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8296 - loss: 0.5086 - val_accuracy: 0.7772 - val_loss: 0.6818\n",
      "Epoch 30/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8210 - loss: 0.4925 - val_accuracy: 0.7574 - val_loss: 0.7278\n",
      "Epoch 31/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8205 - loss: 0.4892 - val_accuracy: 0.7673 - val_loss: 0.7030\n",
      "Epoch 32/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8291 - loss: 0.5099 - val_accuracy: 0.7673 - val_loss: 0.7201\n",
      "Epoch 33/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8396 - loss: 0.4519 - val_accuracy: 0.7673 - val_loss: 0.7092\n",
      "Epoch 34/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8424 - loss: 0.4202 - val_accuracy: 0.8020 - val_loss: 0.6355\n",
      "Epoch 35/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8521 - loss: 0.4211 - val_accuracy: 0.7822 - val_loss: 0.6204\n",
      "Epoch 36/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8712 - loss: 0.3742 - val_accuracy: 0.7970 - val_loss: 0.5993\n",
      "Epoch 37/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8470 - loss: 0.4274 - val_accuracy: 0.7921 - val_loss: 0.6584\n",
      "Epoch 38/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8709 - loss: 0.3781 - val_accuracy: 0.7772 - val_loss: 0.6236\n",
      "Epoch 39/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8802 - loss: 0.3737 - val_accuracy: 0.7574 - val_loss: 0.5848\n",
      "Epoch 40/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8831 - loss: 0.3413 - val_accuracy: 0.7921 - val_loss: 0.5426\n",
      "Epoch 41/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8749 - loss: 0.3537 - val_accuracy: 0.8168 - val_loss: 0.6357\n",
      "Epoch 42/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8921 - loss: 0.3190 - val_accuracy: 0.8069 - val_loss: 0.5940\n",
      "Epoch 43/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8713 - loss: 0.3634 - val_accuracy: 0.8020 - val_loss: 0.5582\n",
      "Epoch 44/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9031 - loss: 0.2827 - val_accuracy: 0.8119 - val_loss: 0.5890\n",
      "Epoch 45/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8757 - loss: 0.3678 - val_accuracy: 0.8069 - val_loss: 0.5793\n",
      "Epoch 46/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8943 - loss: 0.3175 - val_accuracy: 0.8069 - val_loss: 0.5384\n",
      "Epoch 47/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9009 - loss: 0.3037 - val_accuracy: 0.8020 - val_loss: 0.5844\n",
      "Epoch 48/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8979 - loss: 0.3096 - val_accuracy: 0.7822 - val_loss: 0.5503\n",
      "Epoch 49/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9018 - loss: 0.2930 - val_accuracy: 0.8416 - val_loss: 0.5589\n",
      "Epoch 50/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9024 - loss: 0.2857 - val_accuracy: 0.7822 - val_loss: 0.6026\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9133 - loss: 0.2694 - val_accuracy: 0.8119 - val_loss: 0.5734\n",
      "Epoch 52/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9272 - loss: 0.2234 - val_accuracy: 0.8317 - val_loss: 0.6290\n",
      "Epoch 53/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9079 - loss: 0.2674 - val_accuracy: 0.8168 - val_loss: 0.5616\n",
      "Epoch 54/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9248 - loss: 0.2322 - val_accuracy: 0.8416 - val_loss: 0.5946\n",
      "Epoch 55/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9026 - loss: 0.2814 - val_accuracy: 0.8317 - val_loss: 0.6399\n",
      "Epoch 56/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9020 - loss: 0.2824 - val_accuracy: 0.8515 - val_loss: 0.5304\n",
      "Epoch 57/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9227 - loss: 0.2274 - val_accuracy: 0.8168 - val_loss: 0.6262\n",
      "Epoch 58/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9149 - loss: 0.2374 - val_accuracy: 0.8218 - val_loss: 0.5256\n",
      "Epoch 59/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9175 - loss: 0.2453 - val_accuracy: 0.8317 - val_loss: 0.5762\n",
      "Epoch 60/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9048 - loss: 0.2231 - val_accuracy: 0.8119 - val_loss: 0.5920\n",
      "Epoch 61/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9109 - loss: 0.2593 - val_accuracy: 0.8267 - val_loss: 0.5411\n",
      "Epoch 62/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9070 - loss: 0.2442 - val_accuracy: 0.8020 - val_loss: 0.6380\n",
      "Epoch 63/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9267 - loss: 0.2116 - val_accuracy: 0.8218 - val_loss: 0.6591\n",
      "Epoch 64/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9311 - loss: 0.2173 - val_accuracy: 0.8515 - val_loss: 0.4831\n",
      "Epoch 65/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9368 - loss: 0.1777 - val_accuracy: 0.8218 - val_loss: 0.6035\n",
      "Epoch 66/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9198 - loss: 0.2309 - val_accuracy: 0.8069 - val_loss: 0.5436\n",
      "Epoch 67/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9396 - loss: 0.1784 - val_accuracy: 0.8317 - val_loss: 0.5513\n",
      "Epoch 68/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9220 - loss: 0.2096 - val_accuracy: 0.8267 - val_loss: 0.5697\n",
      "Epoch 69/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9439 - loss: 0.1685 - val_accuracy: 0.8366 - val_loss: 0.5623\n",
      "Epoch 70/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9516 - loss: 0.1574 - val_accuracy: 0.8515 - val_loss: 0.5420\n",
      "Epoch 71/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9304 - loss: 0.2097 - val_accuracy: 0.8614 - val_loss: 0.5827\n",
      "Epoch 72/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9244 - loss: 0.2180 - val_accuracy: 0.8515 - val_loss: 0.5942\n",
      "Epoch 73/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9301 - loss: 0.2000 - val_accuracy: 0.8515 - val_loss: 0.5147\n",
      "Epoch 74/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9398 - loss: 0.1580 - val_accuracy: 0.8416 - val_loss: 0.5457\n",
      "Epoch 75/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9439 - loss: 0.1602 - val_accuracy: 0.8416 - val_loss: 0.5501\n",
      "Epoch 76/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9441 - loss: 0.1746 - val_accuracy: 0.8465 - val_loss: 0.5856\n",
      "Epoch 77/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9334 - loss: 0.1813 - val_accuracy: 0.8465 - val_loss: 0.5364\n",
      "Epoch 78/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9235 - loss: 0.2132 - val_accuracy: 0.8515 - val_loss: 0.5168\n",
      "Epoch 79/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9438 - loss: 0.1690 - val_accuracy: 0.8416 - val_loss: 0.5004\n",
      "Epoch 80/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9543 - loss: 0.1409 - val_accuracy: 0.8861 - val_loss: 0.4700\n",
      "Epoch 81/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9435 - loss: 0.1689 - val_accuracy: 0.8564 - val_loss: 0.4907\n",
      "Epoch 82/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9477 - loss: 0.1354 - val_accuracy: 0.8663 - val_loss: 0.5177\n",
      "Epoch 83/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9570 - loss: 0.1395 - val_accuracy: 0.8564 - val_loss: 0.5536\n",
      "Epoch 84/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9649 - loss: 0.1223 - val_accuracy: 0.8416 - val_loss: 0.5101\n",
      "Epoch 85/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9371 - loss: 0.1735 - val_accuracy: 0.8317 - val_loss: 0.5162\n",
      "Epoch 86/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9532 - loss: 0.1648 - val_accuracy: 0.8515 - val_loss: 0.5364\n",
      "Epoch 87/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9531 - loss: 0.1355 - val_accuracy: 0.8317 - val_loss: 0.5902\n",
      "Epoch 88/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9453 - loss: 0.1503 - val_accuracy: 0.8416 - val_loss: 0.5338\n",
      "Epoch 89/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9481 - loss: 0.1556 - val_accuracy: 0.8168 - val_loss: 0.5443\n",
      "Epoch 90/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9515 - loss: 0.1427 - val_accuracy: 0.8614 - val_loss: 0.4610\n",
      "Epoch 91/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9352 - loss: 0.1823 - val_accuracy: 0.8416 - val_loss: 0.5180\n",
      "Epoch 92/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9612 - loss: 0.1315 - val_accuracy: 0.8564 - val_loss: 0.4550\n",
      "Epoch 93/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9620 - loss: 0.1173 - val_accuracy: 0.8614 - val_loss: 0.4779\n",
      "Epoch 94/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9522 - loss: 0.1328 - val_accuracy: 0.8218 - val_loss: 0.5449\n",
      "Epoch 95/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9540 - loss: 0.1246 - val_accuracy: 0.8564 - val_loss: 0.5539\n",
      "Epoch 96/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9551 - loss: 0.1296 - val_accuracy: 0.8515 - val_loss: 0.5578\n",
      "Epoch 97/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9665 - loss: 0.1112 - val_accuracy: 0.8267 - val_loss: 0.5626\n",
      "Epoch 98/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9618 - loss: 0.1264 - val_accuracy: 0.8317 - val_loss: 0.5105\n",
      "Epoch 99/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9573 - loss: 0.1387 - val_accuracy: 0.8366 - val_loss: 0.6418\n",
      "Epoch 100/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9418 - loss: 0.1871 - val_accuracy: 0.8713 - val_loss: 0.4552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Accuracy: 0.8553240740740741\n",
      "Precision: 0.8628777802259316\n",
      "Recall: 0.8553240740740741\n",
      "F1 Score: 0.8569297666750535\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def extract_mfcc(wav_file_name):\n",
    "    y, sr = librosa.load(wav_file_name)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=45).T, axis=0)\n",
    "    return mfcc\n",
    "\n",
    "def extract_stft(wav_file_name):\n",
    "    y, sr = librosa.load(wav_file_name)\n",
    "    stft = np.abs(librosa.stft(y))\n",
    "    stft_mean = np.mean(stft, axis=1)  # Averaging along the time axis\n",
    "    return stft_mean\n",
    "\n",
    "def extract_features(wav_file_name):\n",
    "    mfcc = extract_mfcc(wav_file_name)\n",
    "    stft = extract_stft(wav_file_name)\n",
    "    return np.concatenate((mfcc, stft))\n",
    "\n",
    "ravdess_speech_labels = []\n",
    "ravdess_speech_data = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(r'C:\\Users\\Aprajit Sharma\\Desktop\\Sentiment Analysis\\ravdess'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".wav\"):\n",
    "            ravdess_speech_labels.append(int(filename[7:8])-1)\n",
    "            wav_file_name = os.path.join(dirname, filename)\n",
    "            ravdess_speech_data.append(extract_features(wav_file_name))\n",
    "\n",
    "ravdess_speech_data_array = np.asarray(ravdess_speech_data)\n",
    "ravdess_speech_label_array = np.array(ravdess_speech_labels)\n",
    "\n",
    "print(\"Feature data shape:\", ravdess_speech_data_array.shape)\n",
    "print(\"Labels shape:\", ravdess_speech_label_array.shape)\n",
    "\n",
    "# Prepare the data for training\n",
    "labels_categorical = to_categorical(ravdess_speech_label_array, num_classes=8)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.expand_dims(ravdess_speech_data_array, axis=-1), \n",
    "    labels_categorical, \n",
    "    test_size=0.30, \n",
    "    random_state=9\n",
    ")\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Define and compile the model\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='loss',  \n",
    "    patience=15,          \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "def model_cnn():\n",
    "    input_shape = (ravdess_speech_data_array.shape[1], 1)\n",
    "    model = models.Sequential([\n",
    "        layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(8, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_A = model_cnn()\n",
    "\n",
    "# Train the model\n",
    "history = model_A.fit(x_train, y_train,\n",
    "                      validation_split=0.1,\n",
    "                      epochs=100,\n",
    "                      shuffle=True,\n",
    "                      callbacks=[early_stopping])\n",
    "\n",
    "# Emotion labels\n",
    "emotions = {\n",
    "    0: 'neutral',\n",
    "    1: 'calm',\n",
    "    2: 'happy',\n",
    "    3: 'sad',\n",
    "    4: 'angry',\n",
    "    5: 'fearful',\n",
    "    6: 'disgust',\n",
    "    7: 'surprised'\n",
    "}\n",
    "\n",
    "# Prediction function\n",
    "def predict(wav_filepath):\n",
    "    test_point = extract_features(wav_filepath)\n",
    "    test_point = np.reshape(test_point, newshape=(1, test_point.shape[0], 1))\n",
    "    predictions = model_A.predict(test_point)\n",
    "    print(emotions[np.argmax(predictions[0])])\n",
    "\n",
    "# # Test the predict function\n",
    "# predict('C:/Users/Aprajit Sharma/Desktop/Sentiment Analysis/ravdess/Actor_01/03-01-01-01-01-01-01.wav')\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "predictions = model_A.predict(x_test)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512ccf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "predict('C:/Users/Aprajit Sharma/Desktop/Sentiment Analysis/ravdess/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b16f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_A.save('audio_sentiment_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054881d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
